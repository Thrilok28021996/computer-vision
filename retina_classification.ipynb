{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da4a7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip '/Users/thrilok/Desktop/Datasets/kermany2018.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa0f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3da300",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/Users/thrilok/Documents/computer-vision/OCT2017 /train\"\n",
    "val_path = \"/Users/thrilok/Documents/computer-vision/OCT2017 /val\"\n",
    "test_path = \"/Users/thrilok/Documents/computer-vision/OCT2017 /test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8de66e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 37205/37205 [00:00<00:00, 1218724.02it/s]\n",
      "100%|████████████████████████████████████████████████████| 11348/11348 [00:00<00:00, 1232539.08it/s]\n",
      "100%|██████████████████████████████████████████████████████| 8616/8616 [00:00<00:00, 1236548.27it/s]\n",
      "100%|████████████████████████████████████████████████████| 26315/26315 [00:00<00:00, 1297209.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for target in os.listdir(train_path):\n",
    "    target_path = os.path.join(train_path,target)\n",
    "    for file in tqdm(os.listdir(target_path)):\n",
    "        file_path = os.path.join(target_path,file)\n",
    "        X_train.append(file_path)\n",
    "        Y_train.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3607f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 190650.18it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 250406.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 284359.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 241398.79it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "for target in os.listdir(val_path):\n",
    "    target_path = os.path.join(val_path,target)\n",
    "    for file in tqdm(os.listdir(target_path)):\n",
    "        file_path = os.path.join(target_path,file)\n",
    "        X_val.append(file_path)\n",
    "        Y_val.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eada2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 242/242 [00:00<00:00, 401352.93it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 242/242 [00:00<00:00, 404713.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 242/242 [00:00<00:00, 366698.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 242/242 [00:00<00:00, 279466.29it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for target in os.listdir(test_path):\n",
    "    target_path = os.path.join(test_path,target)\n",
    "    for file in tqdm(os.listdir(target_path)):\n",
    "        file_path = os.path.join(target_path,file)\n",
    "        X_test.append(file_path)\n",
    "        Y_test.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c74a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e76605c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.DataFrame(list(zip(X_train, Y_train)), columns =['image_path', 'label'])\n",
    "df_val = pd.DataFrame(list(zip(X_val,Y_val)), columns=['image_path','label'])\n",
    "df_test = pd.DataFrame(list(zip(X_test,Y_test)), columns=['image_path','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb461ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 83484 validated image filenames belonging to 4 classes.\n",
      "Found 32 validated image filenames belonging to 4 classes.\n",
      "Found 968 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_aug = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    rescale = 1./255,\n",
    "    preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
    ")\n",
    "\n",
    "test_aug = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
    ")\n",
    "\n",
    "train_generator= train_aug.flow_from_dataframe(\n",
    "    dataframe=df_train,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    batch_size=16,\n",
    "    color_mode=\"rgb\",\n",
    "    target_size = (224, 224),\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "val_generator= test_aug.flow_from_dataframe(\n",
    "    dataframe=df_val,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    batch_size=16,\n",
    "    color_mode=\"rgb\",\n",
    "    target_size = (224, 224),\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "test_generator= test_aug.flow_from_dataframe(\n",
    "    dataframe=df_test,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label\",\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=16,\n",
    "    shuffle = False, \n",
    "    target_size = (224, 224),\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b145cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D, MaxPooling2D,AveragePooling2D, BatchNormalization, PReLU, ReLU\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications import InceptionResNetV2\n",
    "\n",
    "def generate_model(pretrained_model = 'vgg16', num_classes=4):\n",
    "    if pretrained_model == 'inceptionv3':\n",
    "        base_model = InceptionV3(weights = 'imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif pretrained_model == 'inceptionresnet':\n",
    "        base_model = InceptionResNetV2(weights = 'imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    else:\n",
    "        base_model = VGG16(weights = 'imagenet', include_top=False, input_shape=(224, 224, 3)) # Topless\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(4096)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    #Freezing Convolutional Base\n",
    "    for layer in base_model.layers[:-3]:\n",
    "        layer.trainable = False  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5590338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, test_generator, num_epochs, optimizer, metrics):\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=metrics)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=6, verbose=1)\n",
    "    rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=7)\n",
    "    print(model.summary())\n",
    "    \n",
    "    history = model.fit(train_generator, epochs=num_epochs, \n",
    "                        validation_data=test_generator, verbose=1,\n",
    "                        callbacks = [early_stop, rlr])\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e883ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "metrics = ['accuracy',\n",
    "                tf.keras.metrics.AUC(),\n",
    "                tfa.metrics.CohenKappa(num_classes = 4),\n",
    "                tfa.metrics.F1Score(num_classes = 4),\n",
    "                tf.keras.metrics.Precision(), \n",
    "                tf.keras.metrics.Recall()]\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    \n",
    "def plot_acc(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    \n",
    "# It prints & plots the confusion matrix, normalization can be applied by setting normalize=True.\n",
    "    \n",
    "def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot_roc_curves(y_true, y_pred, num_classes, class_labels):\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_true)\n",
    "    y_test = lb.transform(y_true)\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    for i in range(num_classes):\n",
    "        fig, c_ax = plt.subplots(1,1, figsize = (6, 4))\n",
    "        c_ax.plot(fpr[i], tpr[i],\n",
    "                 label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "                 ''.format(class_labels[i], roc_auc[i]))\n",
    "        c_ax.set_xlabel('False Positive Rate')\n",
    "        c_ax.set_ylabel('True Positive Rate')\n",
    "        c_ax.set_title('ROC curve of class {0}'.format(class_labels[i]))\n",
    "        c_ax.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    return roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "831439dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, history, test_generator):\n",
    "    # Evaluate model\n",
    "    score = model.evaluate(test_generator, verbose=0)\n",
    "    print('\\nTest set accuracy:', score[1], '\\n')\n",
    "    \n",
    "    y_true = np.array(test_generator.labels)\n",
    "    y_pred = model.predict(test_generator, verbose = 1)\n",
    "    y_pred_classes = np.argmax(y_pred,axis = 1)\n",
    "    class_labels = list(test_generator.class_indices.keys())   \n",
    "    \n",
    "    print('\\n', sklearn.metrics.classification_report(y_true, y_pred_classes, target_names=class_labels), sep='')\n",
    "    confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
    "    plot_acc(history)\n",
    "    plt.show()\n",
    "    plot_loss(history)\n",
    "    plt.show()\n",
    "    plot_confusion_matrix(confusion_mtx, classes = class_labels)\n",
    "    plt.show()\n",
    "    print(\"ROC AUC score:\", plot_roc_curves(y_true, y_pred, 4, class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0be7023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = generate_model('vgg16',4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed1005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thrilok/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "2022-09-05 22:20:01.527292: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 134,276,932\n",
      "Trainable params: 134,276,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 22:20:02.423331: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 419/5218 [=>............................] - ETA: 2:03:40 - loss: 1876148443870781704765440.0000 - accuracy: 0.4558 - auc_4: 0.6960 - cohen_kappa: 8.7839e-04 - f1_score: 0.1649 - precision_3: 0.3032 - recall_3: 0.0070"
     ]
    }
   ],
   "source": [
    "vgg_model, vgg_history = train_model(vgg_model, train_generator, val_generator, 50, tf.keras.optimizers.SGD(lr=0.001, momentum=0.9), metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(vgg_model, vgg_history, test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
